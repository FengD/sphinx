import pytest
from ..sphinx.text_utils import split_long_text, clean_no_need_text, normalize_text

@pytest.fixture
def test_split_long_text():
    text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ã€‚è¿™æ˜¯å¦ä¸€ä¸ªæµ‹è¯•ã€‚è¿™ä¸ªæµ‹è¯•æœ‰ç‚¹é•¿ï¼Œæ‰€ä»¥åº”è¯¥è¢«åˆ†æˆå¤šæ®µã€‚"
    result = split_long_text(text, max_length=10)
    assert len(result) == 4
    assert result[0] == "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ã€‚"
    assert result[1] == "è¿™æ˜¯å¦ä¸€ä¸ªæµ‹è¯•ã€‚"
    assert result[2] == "è¿™ä¸ªæµ‹è¯•æœ‰ç‚¹é•¿ï¼Œ"
    assert result[3] == "æ‰€ä»¥åº”è¯¥è¢«åˆ†æˆå¤šæ®µã€‚"

def test_clean_no_need_text():
    text = "æµ‹è¯•ğŸ˜Šï¼Œå»é™¤è¡¨æƒ…ç¬¦å·ã€‚"
    result = clean_no_need_text(text)
    assert result == "æµ‹è¯•ï¼Œå»é™¤è¡¨æƒ…ç¬¦å·ã€‚"

def test_normalize_text():
    text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•â€¦ï¼Ÿï¼ï¼›è¿™ä¸ªæµ‹è¯•æœ‰ç‰¹æ®Šå­—ç¬¦ï¼šã€ä»¥åŠã€Šã€‹ã€ã€‘"
    result = normalize_text(text)
    assert result == "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ã€‚è¿™ä¸ªæµ‹è¯•æœ‰ç‰¹æ®Šå­—ç¬¦ï¼Œä»¥åŠ"
